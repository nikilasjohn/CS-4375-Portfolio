# CS 4375 Portfolio
 This repo will contain all of the work I do in my Machine Learning class

## Overview of ML
 This pdf contains my answers to the portfolio assignment
 
 You can access the file through [this link](Overview_of_ML.pdf)

## C++ Data Exploration
 This section will detail how I coded functions to calculate the mean, median, range, covariance, and correlation between two variables
 
 The C++ code can be access through [this link](1_C++_Data_Exploration/1_C++_Data_Exp.cpp)
 
 The documentation/overview of this can be accessed through [this link](1_C++_Data_Exploration/1_Documentation.pdf)
 
## Linear Models
 In this assignment, I was able to see the interaction of different regression techniques on a dataset of my choosing.
 
 I chose a dataset which contained all of YouTube's trending videos that appeared in the US over the course of several months.
 
 The notebook I made on Linear Regression can be found [here](2_Linear_Models/Regression.pdf)
 
 The notebook I made on Logical Regression can be found [here](2_Linear_Models/Classification.pdf)
 
 Lastly, the dataset I used can be found in [this directory](2_Linear_Models)

## ML Algorithms From Scratch
 In this assignment, I recreated R commands in C++ to get a deeper understanding on how they work
 
 This assignment called for me to recreate logistic regression (complete) and Naive Bayes (incomplete) using the titanic_project.csv dataset
 The Naive Bayes C++ program is completed up to the final step where you determine the raw data
 
 Code: </br>
  [Logistic Regression](3_Scratch_Algorithms/LogReg.cpp) </br>
  [Naive Bayes](3_Scratch_Algorithms/NBayes.cpp)
 
 The report can be accessed [here](3_Scratch_Algorithms/Overview.pdf)
 
## Similarity
 In this assignment, I worked with three other classmates in creating different similarity models, using different clustering methods, and dimensionality
 reduction techniques. We also wrote a document detailing the characteristics of these different ML algorithms.
 
 Notebooks:</br>
  [Regression](4_Similarity/Regression.pdf)</br>
  [Classification](4_Similarity/Classification.pdf)</br>
  [Clustering](4_Similarity/Clustering.pdf)</br>
  [Dimensionality Reduction](4_Similarity/DimensionalityReduction.pdf)
  
 Documentation:</br>
  [Narrative document](4_Similarity/Narrative.pdf)
  
## Kernel/Ensemble Methods
 In this assignment, I worked with a partner to gain experience on SVM linear, polynomial, and radial kernels. We also learned about Ensemble techniques used
 to boost a data set. The three ensemble methods we used were Random Forest, XGBoost, and Adaboost. We also wrote a document stating how the algorithms work, 
 their applications, and their advantages/disadvantages
 
 Notebooks:</br>
  [Regression](5_Kernel_Ensemble/SVM_Regression.pdf)</br>
  [Classification](5_Kernel_Ensemble/SVM_Classification.pdf)</br>
  [Ensemble Methods](5_Kernel_Ensemble/Ensemble.pdf)</br>
 
 Documentation:</br>
  [Narrative document](5_Kernel_Ensemble/Narrative.pdf)
  
 ## ML with Sklearn
  In this assignment, I worked on learning how to use machine learning in Python, specifically using the Sklearn library. This gave me hands on experience on   the differences between using Python and R. I used Google CoLab to create the notebook and honestly had a great time using it. It is very stream lined, and   for being a cloud-based machine learning IDE, it runs surprisingly fast. However, I am sure once the data sets become as big as the industry norm, then       there will be some problems with execution time.
  
  Notebooks:<br>
   [MLsklearn](6_MLsklearn/MLsklearn.pdf)
   
## Image Classification <br>
 In this assignment, I worked with image datasets to test different Deep Learning algorithms with the purpose of classifying them. I used a dataset of dogs and cats to see if the machine could predict if the photo was a either a dog or a cat. This assignment is NOT COMPLETE due to my lack of understanding over the subject matter, but I hope to one day come back and finish it. This was the slowest I've seen an ML algorithm run, with the longest time being 66 minutes to execute.
 
  Notebooks:<br>
   [Image Classification](7_Image_Classification/7_Image_Classification.pdf)
